# Training-Konfiguration

training:
  # Zeitstruktur
  steps_per_episode: 250      # 1 Episode = 1 Jahr = 250 Betriebstage
  num_episodes: 5000          # 5000 Episoden = 5000 simulierte Jahre
  total_timesteps: 1250000    # = steps_per_episode * num_episodes
  
  # PPO Hyperparameter
  algorithm: "PPO"
  learning_rate: 0.0003       # 3e-4 (Standard)
  n_steps: 2048               # Steps pro Update
  batch_size: 64
  n_epochs: 10
  gamma: 0.99                 # Discount factor
  
  # Checkpoints
  checkpoint_freq: 250000     # Alle 250k steps = alle 1000 Episoden (simulierte Jahre)
  
  # Logging
  tensorboard: true
  log_interval: 10            # Alle 10 Episoden loggen
  
  # Environment
  env_id: "MultiAgentEconomy-v0"
